{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1677,"status":"ok","timestamp":1702377754285,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"gTl-p_IHwb1k"},"outputs":[],"source":["import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702377754286,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"D6rpYH4bxGF-"},"outputs":[],"source":["\n","import os\n","from google.colab import drive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"elapsed":17504,"status":"error","timestamp":1702377771775,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"2OGZbTKswxtR","outputId":"1450c22c-9e0d-41e0-938d-ab7d49ff8ce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c186f98dc98d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/IE434_ProjectGroup7/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrides_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Merged_Data.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrides_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'started_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrides_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'started_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/IE434_ProjectGroup7/'"]}],"source":["drive.mount('/content/drive')\n","pwd = \"/content/drive/My Drive/IE434_ProjectGroup7/\"\n","os.chdir(pwd)\n","rides_data=pd.read_pickle('Merged_Data.pkl')\n","rides_data['started_at']=pd.to_datetime(rides_data['started_at'])\n","rides_data['ended_at']=pd.to_datetime(rides_data['ended_at'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1702377771777,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"elLKCYxBw5CW"},"outputs":[],"source":["rides_data.sort_values(by=['started_at'],inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1702377771777,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"SPxN-HBxTWWc"},"outputs":[],"source":["rides_data['member_casual'] = np.where((rides_data['member_casual'] == 'casual') | (rides_data['member_casual'] == 'Customer'), 'casual', rides_data['member_casual'])\n","rides_data['member_casual'] = np.where((rides_data['member_casual'] == 'member') | (rides_data['member_casual'] == 'Subscriber'), 'member', rides_data['member_casual'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1702377771777,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"--SJQfLk4qwo"},"outputs":[],"source":["\n","rides_data=rides_data.drop(columns=['member_casual','distance','duration','DATE', 'TEMP', 'VISIB', 'WDSP', 'MAX', 'MIN', 'PRCP','start_date', 'start_time', 'end_date',\n","       'end_time'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771778,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"c0VV-3Ga5WFU"},"outputs":[],"source":["rides_data.columns"]},{"cell_type":"markdown","metadata":{"id":"WkPymetzzUhf"},"source":["## Preparing features from the raw data."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771778,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"45Uo8DMZ585a"},"outputs":[],"source":["rides_data.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771778,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"ej-n15ICBdMG"},"outputs":[],"source":["rides_data['end_station_name'].isna().value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771778,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"yJqZwzC6-6W4"},"outputs":[],"source":["import pandas as pd\n","\n","rides_data['started_at'] = pd.to_datetime(rides_data['started_at'])\n","rides_data['ended_at'] = pd.to_datetime(rides_data['ended_at'])\n","\n","rides_data['day_of_week'] = rides_data['started_at'].dt.dayofweek\n","rides_data['year'] = rides_data['started_at'].dt.year\n","rides_data['hour_of_day'] = rides_data['started_at'].dt.hour\n","rides_data['month'] = rides_data['started_at'].dt.month\n","\n","rides_data['date'] = rides_data['started_at'].dt.date\n","\n","\n","aggregated_data = pd.DataFrame()\n","\n","\n","outgoing_rides = rides_data.groupby(['start_station_name', 'date','year', 'month','day_of_week', 'hour_of_day']).size().reset_index(name='total_rides_out')\n","incoming_rides = rides_data.groupby(['end_station_name', 'date','year',  'month','day_of_week', 'hour_of_day']).size().reset_index(name='total_rides_in')\n","\n","\n","outgoing_rides.rename(columns={'start_station_name':'Station'},inplace=True)\n","incoming_rides.rename(columns={'end_station_name':'Station'},inplace=True)\n","\n","aggregated_data = pd.merge(outgoing_rides, incoming_rides, left_on=['Station', 'date','year', 'month','day_of_week', 'hour_of_day'],right_on=['Station', 'date','year', 'month', 'day_of_week', 'hour_of_day'], how='outer')\n","\n","aggregated_data['total_rides_out'] = aggregated_data['total_rides_out'].fillna(0)\n","aggregated_data['total_rides_in'] = aggregated_data['total_rides_in'].fillna(0)\n","\n","\n","aggregated_data['Bike_demand'] = aggregated_data['total_rides_out'] - aggregated_data['total_rides_in']\n","\n","\n","aggregated_data = aggregated_data[['Station', 'date','year',  'month','day_of_week', 'hour_of_day', 'total_rides_out', 'total_rides_in', 'Bike_demand']]\n","\n","aggregated_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1702377771779,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"BUKKP1aECBdf"},"outputs":[],"source":["aggregated_data.sort_values(by=['date','hour_of_day'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771779,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"AbDIuS3JUlX-"},"outputs":[],"source":["aggregated_data.sort_values(by=['date'],ascending=True,inplace=True)\n","aggregated_data.reset_index(drop=True,inplace=True)\n","aggregated_data['Station'].nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771779,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"pZLnZcL0-vIy"},"outputs":[],"source":["hot_encoded_stations = pd.get_dummies(aggregated_data['Station'])\n","aggregated_data = pd.concat([aggregated_data, hot_encoded_stations], axis=1)\n","aggregated_data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771779,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"mS1856YuXq0j"},"outputs":[],"source":["Y_out=aggregated_data[['date','year','total_rides_out']]\n","Y_in=aggregated_data[['date','year','total_rides_in']]\n","X=aggregated_data.drop(columns=['total_rides_out','total_rides_in','Station','Bike_demand'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771780,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"1Fo5HKVhyyDH"},"outputs":[],"source":["X_test=X[X['year']>2022]\n","X_train=X[(X['year']<=2022)&(X['year']>2021)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771780,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"YKrydDu8yE-M"},"outputs":[],"source":["y_test_out=Y_out[Y_out['year']>2022]\n","y_test_in=Y_in[Y_in['year']>2022]\n","y_train_out=Y_out[(Y_out['year']<=2022)&(Y_out['year']>2021)]\n","y_train_in=Y_in[(Y_in['year']<=2022)&(Y_in['year']>2021)]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771780,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"ihQ5io-p0v2y"},"outputs":[],"source":["X_train.drop(columns=['date'],inplace=True)\n","y_train_out.drop(columns=['date','year'],inplace=True)\n","y_train_in.drop(columns=['date','year'],inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771780,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"sfnisBu3KMBf"},"outputs":[],"source":["X_test.drop(columns=['date'],inplace=True)\n","y_test_out.drop(columns=['date','year'],inplace=True)\n","y_test_in.drop(columns=['date','year'],inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771780,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"ZrmUshA_K8Oa"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771781,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"cxslHdsmL5JK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1702377771781,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"9ryxmeqMK8R1"},"outputs":[],"source":["X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n","y_train_in_tensor = torch.tensor(y_train_in.values, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n","y_test_in_tensor = torch.tensor(y_test_in.values, dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1702377771781,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"0YJVJxylOqFS"},"outputs":[],"source":["\n","train_dataset = TensorDataset(X_train_tensor, y_train_in_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"e-2Vz7n_rN6m"},"source":["## Implementing a simple feed forward network as the baseline model.\n","\n","### The objective is to find the count of outgoing and incoming rides at all stations for every 1 hour timeslot."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1702377771781,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"SOXlLLtYK8Uq"},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(X_train.shape[1], 64)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1702377771781,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"qbn5ICF3K8Xl"},"outputs":[],"source":["\n","model = SimpleNN()\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1wZw27sK8a7","executionInfo":{"status":"aborted","timestamp":1702377771781,"user_tz":360,"elapsed":14,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","\n","\n","train_losses = []\n","val_losses = []\n","\n","\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_test_tensor)\n","        val_loss = criterion(val_outputs, y_test_in_tensor)\n","        val_losses.append(val_loss.item())\n","\n","y_pred_in = val_outputs.detach().numpy()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNS5lz17SgQU","executionInfo":{"status":"aborted","timestamp":1702377771782,"user_tz":360,"elapsed":15,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["y_train_out_tensor = torch.tensor(y_train_out.values, dtype=torch.float32)\n","\n","y_test_out_tensor = torch.tensor(y_test_out.values, dtype=torch.float32)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z35y-INeSgS6","executionInfo":{"status":"aborted","timestamp":1702377771782,"user_tz":360,"elapsed":15,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["train_dataset = TensorDataset(X_train_tensor, y_train_out_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCFJxrgn1bj0","executionInfo":{"status":"aborted","timestamp":1702377771782,"user_tz":360,"elapsed":14,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["model = SimpleNN()\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gc7MR4jL2RjH","executionInfo":{"status":"aborted","timestamp":1702377771784,"user_tz":360,"elapsed":16,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","\n","\n","train_losses_out = []\n","val_losses_out = []\n","\n","\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses_out.append(loss.item())\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        val_outputs = model(X_test_tensor)\n","        val_loss = criterion(val_outputs, y_test_in_tensor)\n","        val_losses_out.append(val_loss.item())\n","\n","y_pred_out = val_outputs.detach().numpy()"]},{"cell_type":"markdown","metadata":{"id":"fob7mbfMq2vc"},"source":["## Calculation of Loss and Metric of the Baseline Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oNhmVAXWbef","executionInfo":{"status":"aborted","timestamp":1702377771784,"user_tz":360,"elapsed":19636,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["rmse_in = mean_squared_error(y_test_in_tensor.numpy(), y_pred_in, squared=False)\n","mae_in = mean_absolute_error(y_test_in_tensor.numpy(), y_pred_in)\n","\n","\n","rmse_out = mean_squared_error(y_test_out_tensor.numpy(), y_pred_out, squared=False)\n","mae_out = mean_absolute_error(y_test_out_tensor.numpy(), y_pred_out)\n","\n","\n","print(f\"RMSE (y_test_in): {rmse_in}\")\n","print(f\"MAE (y_test_in): {mae_in}\")\n","\n","print(f\"RMSE (y_test_out): {rmse_out}\")\n","print(f\"MAE (y_test_out): {mae_out}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHNGqn64qzEx","executionInfo":{"status":"aborted","timestamp":1702377771784,"user_tz":360,"elapsed":19633,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"}}},"outputs":[],"source":["# Function to calculate feature importance using random permutations\n","def calculate_feature_importance(model, X, y_true, feature_names, criterion, n_permutations=30):\n","    baseline_loss = criterion(model(X), y_true).item()\n","    feature_importance = []\n","\n","    for idx, feature in enumerate(feature_names):\n","        permuted_X = X.clone()\n","        permuted_X[:, idx] = torch.tensor(np.random.permutation(permuted_X[:, idx]), dtype=torch.float32)\n","        permuted_loss = criterion(model(permuted_X), y_true).item()\n","        feature_importance.append((feature, baseline_loss - permuted_loss))\n","\n","    # Sort feature importance in descending order\n","    feature_importance.sort(key=lambda x: x[1], reverse=True)\n","\n","    return feature_importance\n","\n","# Get feature names from the DataFrame (assuming X_train is a DataFrame)\n","feature_names = list(X_train.columns)\n","\n","# Calculate feature importance for rides into a station\n","feature_importance_in = calculate_feature_importance(model, X_test_tensor, y_test_in_tensor, feature_names, criterion)\n","\n","# Calculate feature importance for rides out a station\n","feature_importance_out = calculate_feature_importance(model, X_test_tensor, y_test_out_tensor, feature_names, criterion)\n","\n","# Display feature importance\n","print(\"Feature Importance (Number of Rides In ):\")\n","for feature, importance in feature_importance_in:\n","    print(f\"{feature}: {importance}\")\n","\n","print(\"\\nFeature Importance (Number of Rides Out ):\")\n","for feature, importance in feature_importance_out:\n","    print(f\"{feature}: {importance}\")\n"]},{"cell_type":"markdown","metadata":{"id":"5zBXh93tuN7E"},"source":["This is the feature importance for the baseline model, this has been done to meet he milestone requirement. However, we have not used this feature importance for any tangible outcome. This is to show a postivie correation between day of the week and the rides takes. Other fearures considered are hour_of_week."]},{"cell_type":"markdown","metadata":{"id":"qstU5n-2wfzL"},"source":["### Feature Importance (Number of Rides In):\n","- **Year**: 0.0 (insignificant impact on predictions for rides in). Permuting or changing the values of the year feature didn't significantly affect the model's prediction for the number of rides in.\n","- **Day of Week**: -0.045 (minor impact on predictions for rides in). The model's performance decreased by approximately 0.045, indicating a slight impact on predictions.\n","- **Month**: -0.477 (relatively important for predicting rides in). The model's performance decreased by approximately 0.477, implying that the month feature has more influence on predictions compared to the year or day of the week for rides into the station.\n","- **Hour of Day**: -1.015 (most influential feature for predicting rides in). The hour of the day is the most influential feature among the listed features, with a decrease in model performance of around 1.015. This suggests that the hour of the day significantly impacts the predictions for rides into the station.\n","\n","### Feature Importance (Number of Rides Out):\n","- **Year**: 0.0 (insignificant impact on predictions for rides out). Similar to the rides in scenario, the year feature's importance is calculated as 0.0, indicating it doesn't significantly affect predictions for the number of rides out.\n","- **Day of Week**: -0.045 (minor impact on predictions for rides out). Similar to rides in, the day of the week feature has a minor impact of approximately -0.045 on predictions for rides out of the station.\n","- **Month**: -0.457 (relatively important for predicting rides out). Like in the rides in scenario, the month feature is relatively important for predicting rides out, with a decrease in model performance of approximately -0.457.\n","- **Hour of Day**: -1.007 (most influential feature for predicting rides out). Similar to rides in, the hour of the day is the most influential feature for predicting the number of rides out, with a decrease in model performance of around -1.007.\n"]},{"cell_type":"markdown","metadata":{"id":"H3ees_dGxhf3"},"source":["The above values are based on the change in the model's performance(loss) when each feature is randomly permuted,suggesting their relative significane in making predictions for the number of rides into or out of the station."]},{"cell_type":"markdown","metadata":{"id":"fT8P3JRzsGJK"},"source":["As in the second part of the our analysis we used the STGCN model we have implemeted the clustered spatial and temporal features that are lattitues and longitutes and station names/ station ids. We have used a window for 30 mins for predicting net rides to those stations. As the model uses  only these 4 features to predict the net rides. These are the only features considered. This A STGCN model doen't not have a feature importance matrix as all the features are used to train."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19631,"status":"aborted","timestamp":1702377771785,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"QwI8QLuE8VW0"},"outputs":[],"source":["\n","# Function to calculate feature importance using random permutations\n","def calculate_feature_importance(model, X, y_true, feature_names, criterion, n_permutations=30):\n","    baseline_loss = criterion(model(X), y_true).item()\n","    feature_importance = []\n","\n","    for idx, feature in enumerate(feature_names):\n","        permuted_X = X.clone()\n","        permuted_X[:, idx] = torch.tensor(np.random.permutation(permuted_X[:, idx]), dtype=torch.float32)\n","        permuted_loss = criterion(model(permuted_X), y_true).item()\n","        feature_importance.append((feature, baseline_loss - permuted_loss))\n","\n","    # Sort feature importance in descending order\n","    feature_importance.sort(key=lambda x: x[1], reverse=True)\n","\n","    return feature_importance\n","\n","# Get feature names from the DataFrame (assuming X_train is a DataFrame)\n","feature_names = list(X_train.columns)\n","\n","# Calculate feature importance for rides into a station\n","feature_importance_in = calculate_feature_importance(model, X_test_tensor, y_test_in_tensor, feature_names, criterion)\n","\n","# Calculate feature importance for rides out a station\n","feature_importance_out = calculate_feature_importance(model, X_test_tensor, y_test_out_tensor, feature_names, criterion)\n","\n","# Display feature importance\n","print(\"Feature Importance (Number of Rides In ):\")\n","for feature, importance in feature_importance_in:\n","    print(f\"{feature}: {importance}\")\n","\n","print(\"\\nFeature Importance (Number of Rides Out ):\")\n","for feature, importance in feature_importance_out:\n","    print(f\"{feature}: {importance}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19627,"status":"aborted","timestamp":1702377771785,"user":{"displayName":"Ayse Dogan","userId":"17299110129555462884"},"user_tz":360},"id":"zF-GU7a1y1Zo"},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","def calculate_feature_importance(model, X, y_true, criterion, n_permutations=30):\n","    baseline_loss = criterion(model(X), y_true).item()\n","    feature_importance = []\n","\n","    for idx in range(X.shape[1]):\n","        permuted_losses = []\n","        for _ in range(n_permutations):\n","            permuted_X = X.clone()\n","            permuted_X[:, idx] = torch.tensor(np.random.permutation(permuted_X[:, idx]), dtype=torch.float32)\n","            permuted_loss = criterion(model(permuted_X), y_true).item()\n","            permuted_losses.append(permuted_loss)\n","\n","        average_permuted_loss = np.mean(permuted_losses)\n","        feature_importance.append((idx, baseline_loss - average_permuted_loss))\n","\n","    # Sort feature importance in descending order\n","    feature_importance.sort(key=lambda x: x[1], reverse=True)\n","\n","    return feature_importance\n","\n","# Assuming X_train and X_test_tensor are defined elsewhere\n","# Assuming model and criterion are defined elsewhere\n","\n","# Get feature names from the number of columns in X_train\n","feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]\n","\n","# Convert X_train to a PyTorch tensor\n","X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n","\n","# Convert X_test to a PyTorch tensor\n","X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n","\n","# Assuming y_train and y_test are defined and converted to PyTorch tensors\n","# Calculate feature importance for rides into a station\n","feature_importance_in = calculate_feature_importance(model, X_test_tensor, y_test_in_tensor, criterion)\n","\n","# Calculate feature importance for rides out a station\n","feature_importance_out = calculate_feature_importance(model, X_test_tensor, y_test_out_tensor, criterion)\n","\n","# Map indices to feature names for readability\n","feature_importance_in_named = [(feature_names[idx], importance) for idx, importance in feature_importance_in]\n","feature_importance_out_named = [(feature_names[idx], importance) for idx, importance in feature_importance_out]\n","\n","# Display feature importance\n","print(\"Feature Importance (Number of Rides In):\")\n","for feature, importance in feature_importance_in_named:\n","    print(f\"{feature}: {importance}\")\n","\n","print(\"\\nFeature Importance (Number of Rides Out):\")\n","for feature, importance in feature_importance_out_named:\n","    print(f\"{feature}: {importance}\")\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"10vi4mVfncuXSaQLTEMKQXof_3f5oBmsg","timestamp":1701927153157},{"file_id":"1JFb8jQbRN5bGwWyEDietcZKsekpn72vN","timestamp":1701856285876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}